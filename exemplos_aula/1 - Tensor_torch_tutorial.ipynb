{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"lCz3tqDCbaPi","executionInfo":{"status":"ok","timestamp":1743513402074,"user_tz":180,"elapsed":15,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}}},"outputs":[],"source":["# For tips on running notebooks in Google Colab, see\n","# https://pytorch.org/tutorials/beginner/colab\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"5KIxf1wXbaPl"},"source":["\n","Tensors\n","=======\n","\n"]},{"cell_type":"markdown","source":["\n","![imagem](https://drive.google.com/uc?id=1yu5MuPb6e_VPsJuCW0rX_URtZPXF1Vms)\n","Três atributos principais definem um tensor:\n","\n","* **Rank (Ordem)**\n","\n","* **Shape (Forma)**\n","\n","* **Tipo de dado**\n","\n","Aqui, a ordem de um tensor se refere ao número de eixos do tensor.\n","\n","Exemplos:\n","\n","A ordem de uma matriz é 2 porque ela possui dois eixos.\n","\n","A ordem de um vetor é 1 porque ele possui um único eixo.\n","\n","A forma de um tensor se refere ao número de dimensões ao longo de cada eixo.\n","\n","Exemplo:\n","\n","Uma matriz quadrada pode ter dimensões (2, 2).\n","\n","Um tensor de ordem 3 pode ter dimensões (3, 5, 8).\n","\n","O tipo de dado de um tensor se refere ao tipo de dados que ele contém.\n","\n","Aqui estão alguns dos tipos de dados suportados:\n","* float32\n","* float64\n","* uint8\n","* int32\n","* int64\n"],"metadata":{"id":"i8OhgAsAbja_"}},{"cell_type":"markdown","source":["## Um escalar (tensor 0D)\n","Possui ordem 0 e contém um único número.\n"],"metadata":{"id":"W9MihSbQpHvs"}},{"cell_type":"code","source":["import numpy as np\n","\n","tensor = np.array(42)\n","tensor.shape"],"metadata":{"id":"GtoRFiJ9ooAr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513402092,"user_tz":180,"elapsed":12,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"144493bf-2810-424b-890c-e14633ed2a91"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["()"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["tensor.ndim"],"metadata":{"id":"rm1ZCHixpBr4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513402135,"user_tz":180,"elapsed":25,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"7c1fa101-d6f3-4adf-b941-9787123498b3"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## Um vetor (tensor 1D)\n","Possui ordem 1 e representa um array de números.\n"],"metadata":{"id":"SxZFCQRepLvO"}},{"cell_type":"code","source":["import numpy as np\n","\n","tensor = np.array([8,16,32,64])\n","tensor.shape"],"metadata":{"id":"iKkNVJr2pO1j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513402177,"user_tz":180,"elapsed":41,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"495ba684-d737-4fc2-96bd-6fd8d66b954e"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4,)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["tensor.ndim"],"metadata":{"id":"fUyUjJnwqa9z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513402201,"user_tz":180,"elapsed":24,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"1bca2c10-fd95-4f5b-f2c4-9b944df919bc"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Uma matriz (tensor 2D)\n","Possui ordem 2 e representa um array de vetores. Os dois eixos de uma matriz são geralmente chamados de linhas e colunas.\n"],"metadata":{"id":"FxGsFMzdqhtg"}},{"cell_type":"code","source":["import numpy as np\n","\n","tensor = np.array([[2,10,12,24],\n","                   [8,16,32,64],\n","                   [5,10,15,20]])\n","tensor.shape"],"metadata":{"id":"huMvT9Tvqi_9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513402223,"user_tz":180,"elapsed":21,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"d2fa3588-df3b-42eb-fadf-42b46ec3fb3a"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, 4)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["tensor.ndim"],"metadata":{"id":"cj2irbvCqyUY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513402246,"user_tz":180,"elapsed":22,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"f1273a6b-1d55-4138-de24-4a312de87686"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Aqui estão algumas representações comuns de tensores:\n","\n","Vetores: 1D — (features)\n","\n","Sequências: 2D — (timesteps, features)\n","\n","Imagens: 3D — (altura, largura, canais)\n","\n","Vídeos: 4D — (frames, altura, largura, canais)\n","\n","Geralmente, os algoritmos de machine learning lidam com um subconjunto de dados por vez, chamado **batch**.\n","\n","Ao usar um batch de dados, o primeiro eixo do tensor é reservado para o tamanho do batch (número de amostras).\n","\n","Por exemplo, se você estiver lidando com tensores 2D (matrizes), um batch delas terá um total de 3 dimensões:\n","\n","* (exemplos, linhas, colunas)\n","\n","Observe que o primeiro eixo é o número de matrizes que temos no nosso batch.\n","\n","Seguindo a mesma lógica, um batch de imagens pode ser representado como um tensor 4D:\n","\n","* (exemplos, altura, largura, canais)\n","\n","E um batch de vídeos como um tensor 5D:\n","\n","* (exemplos, frames, altura, largura, canais)\n"],"metadata":{"id":"jb5M5-V4pT7Z"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"yenj6bbnbaPm","executionInfo":{"status":"ok","timestamp":1743513406753,"user_tz":180,"elapsed":4506,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}}},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"code","source":["\n","print(\"torch version:\",torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQelizYtcQuT","executionInfo":{"status":"ok","timestamp":1743513406764,"user_tz":180,"elapsed":10,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"1f70d79b-54a5-46fc-ca67-d2a231e476fe"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch version: 2.6.0+cu124\n"]}]},{"cell_type":"markdown","metadata":{"id":"WbwtmtdGbaPm"},"source":["Initializing a Tensor\n","=====================\n","In PyTorch, we use tensors to encode the inputs and\n","outputs of a model, as well as the model's parameters.\n","\n","Tensors are similar to [NumPy's](https://numpy.org/) ndarrays, except\n","that tensors can run on GPUs or other hardware accelerators. In fact,\n","tensors and NumPy arrays can often share the same underlying memory,\n","eliminating the need to copy data (see\n","`bridge-to-np-label`{.interpreted-text role=\"ref\"}). Tensors are also\n","optimized for automatic differentiation (we\\'ll see more about that\n","later in the [Autograd](autogradqs_tutorial.html) section). If you're\n","familiar with ndarrays, you'll be right at home with the Tensor API. If\n","not, follow along!\n","\n","\n","----\n","Tensors can be initialized in various ways. Take a look at the following\n","examples:\n","\n","**Directly from data**\n","\n","Tensors can be created directly from data. The data type is\n","automatically inferred.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ylL-3zxgbaPm","executionInfo":{"status":"ok","timestamp":1743513406777,"user_tz":180,"elapsed":2,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}}},"outputs":[],"source":["data = [[1, 2],[3, 4]]\n","x_data = torch.tensor(data)"]},{"cell_type":"markdown","metadata":{"id":"6QTetpTHbaPm"},"source":["**From a NumPy array**\n","\n","Tensors can be created from NumPy arrays (and vice versa - see\n","`bridge-to-np-label`{.interpreted-text role=\"ref\"}).\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"AbHpkI8LbaPn","executionInfo":{"status":"ok","timestamp":1743513406806,"user_tz":180,"elapsed":19,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}}},"outputs":[],"source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)"]},{"cell_type":"markdown","metadata":{"id":"Zx21_b7fbaPn"},"source":["**From another tensor:**\n","\n","The new tensor retains the properties (shape, datatype) of the argument\n","tensor, unless explicitly overridden.\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Pyd5JD9UbaPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513406893,"user_tz":180,"elapsed":85,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"7a28ab95-6f1e-4360-bd8d-6ce96bf8fa6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Ones Tensor: \n"," tensor([[0, 0],\n","        [0, 0]]) \n","\n","Random Tensor: \n"," tensor([[0.5845, 0.8061],\n","        [0.3473, 0.0972]]) \n","\n"]}],"source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","x_ones = torch.zeros_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"__ccoWehbaPn"},"source":["**With random or constant values:**\n","\n","`shape` is a tuple of tensor dimensions. In the functions below, it\n","determines the dimensionality of the output tensor.\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"BJ8DBaiUbaPo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513406939,"user_tz":180,"elapsed":41,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"27d0ed3e-f8ed-4890-9eb6-a40f7b6c5e40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.8544, 0.5697, 0.9979],\n","        [0.2388, 0.9922, 0.4096]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["shape = (2,3,)\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","#zeros_tensor = torch.zeros(shape,dtype=torch.int)\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")"]},{"cell_type":"markdown","metadata":{"id":"r4D7yR6PbaPo"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"sghdb33nbaPo"},"source":["Attributes of a Tensor\n","======================\n","\n","Tensor attributes describe their shape, datatype, and the device on\n","which they are stored.\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"nV5jN_6WbaPo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513406970,"user_tz":180,"elapsed":3,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"6a36ac13-3b84-4eec-8b55-3a94224ddf2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3,4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"NcrD2CDnbaPo"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"ByrTAwmRbaPo"},"source":["Operations on Tensors\n","=====================\n","\n","Over 1200 tensor operations, including arithmetic, linear algebra,\n","matrix manipulation (transposing, indexing, slicing), sampling and more\n","are comprehensively described\n","[here](https://pytorch.org/docs/stable/torch.html).\n","\n","Each of these operations can be run on the CPU and\n","[Accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n","such as CUDA, MPS, MTIA, or XPU. If you're using Colab, allocate an\n","accelerator by going to Runtime \\> Change runtime type \\> GPU.\n","\n","By default, tensors are created on the CPU. We need to explicitly move\n","tensors to the accelerator using `.to` method (after checking for\n","accelerator availability). Keep in mind that copying large tensors\n","across devices can be expensive in terms of time and memory!\n"]},{"cell_type":"code","source":["tensor = tensor.to('cuda:0')\n","print(f\"Device tensor is stored on: {tensor.device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMp5EZOuhnmy","executionInfo":{"status":"ok","timestamp":1743514265143,"user_tz":180,"elapsed":5,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"cdbb9ace-34b6-47c5-b40e-6d60c180e1f6"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Device tensor is stored on: cuda:0\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"id":"RJ0XTKzybaPo","executionInfo":{"status":"ok","timestamp":1743513407263,"user_tz":180,"elapsed":14,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}}},"outputs":[],"source":["# We move our tensor to the current accelerator if available\n","if torch.accelerator.is_available():\n","    tensor = tensor.to(torch.accelerator.current_accelerator())"]},{"cell_type":"markdown","metadata":{"id":"Cs_usdKQbaPo"},"source":["Try out some of the operations from the list. If you\\'re familiar with\n","the NumPy API, you\\'ll find the Tensor API a breeze to use.\n"]},{"cell_type":"markdown","metadata":{"id":"yN8T6E2GbaPo"},"source":["**Standard numpy-like indexing and slicing:**\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"RD4x9APWbaPo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513407300,"user_tz":180,"elapsed":15,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"9253c8bb-79ff-4ec1-b7d0-8967786c2d31"},"outputs":[{"output_type":"stream","name":"stdout","text":["First row: tensor([1., 1., 1., 1.])\n","First column: tensor([1., 1., 1., 1.])\n","Last column: tensor([1., 1., 1., 1.])\n","tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}],"source":["tensor = torch.ones(4, 4)\n","print(f\"First row: {tensor[0]}\")\n","print(f\"First column: {tensor[:, 0]}\")\n","print(f\"Last column: {tensor[..., -1]}\")\n","tensor[:,1] = 0\n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"96L_qurpbaPp"},"source":["**Joining tensors** You can use `torch.cat` to concatenate a sequence of\n","tensors along a given dimension. See also\n","[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html),\n","another tensor joining operator that is subtly different from\n","`torch.cat`.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"2x0_6y_kbaPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513407574,"user_tz":180,"elapsed":2,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"8caf8c79-f05c-4b98-cad6-8e4a545b0682"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}],"source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\n","print(t1)"]},{"cell_type":"code","source":["t1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8UUCpRwjBQ5","executionInfo":{"status":"ok","timestamp":1743513407590,"user_tz":180,"elapsed":16,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"da3f297e-03e3-420d-c774-a28a0f25ef17"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 12])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["t1 = torch.cat([tensor, tensor, tensor], dim=0)\n","print(t1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8Iw_NiXi98Z","executionInfo":{"status":"ok","timestamp":1743513407608,"user_tz":180,"elapsed":18,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"1f82e350-a8ef-40ae-bd8b-ca4080fb7941"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}]},{"cell_type":"code","source":["t1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnIZB7j7iwNt","executionInfo":{"status":"ok","timestamp":1743513407627,"user_tz":180,"elapsed":18,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"55d4afbf-2fd4-45ae-e0db-8274e8cc47d4"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 4])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"0ZvO5xdFbaPp"},"source":["**Arithmetic operations**\n"]},{"cell_type":"code","source":["tensor.T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLJQIEvikIyd","executionInfo":{"status":"ok","timestamp":1743514571874,"user_tz":180,"elapsed":48,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"2ef33f1c-2f87-43cf-9be2-409466ed0708"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[18., 18., 18., 18.],\n","        [15., 15., 15., 15.],\n","        [18., 18., 18., 18.],\n","        [18., 18., 18., 18.]], device='cuda:0')"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIkMiDx0kRmN","executionInfo":{"status":"ok","timestamp":1743514577218,"user_tz":180,"elapsed":5,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"f45c720f-881a-4ec9-e6f1-06c47c77eaf4"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[18., 15., 18., 18.],\n","        [18., 15., 18., 18.],\n","        [18., 15., 18., 18.],\n","        [18., 15., 18., 18.]], device='cuda:0')"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","execution_count":22,"metadata":{"id":"OlP7ESmdbaPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513407663,"user_tz":180,"elapsed":36,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"2a9aa96a-0ff1-4944-b68e-bca7a1af7a74"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])"]},"metadata":{},"execution_count":22}],"source":["# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n","# ``tensor.T`` returns the transpose of a tensor\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","print(torch.allclose(y1, y2))\n","\n","y3 = torch.rand_like(y1)\n","torch.matmul(tensor, tensor.T, out=y3)\n","\n","\n","# This computes the element-wise product. z1, z2, z3 will have the same value\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)"]},{"cell_type":"markdown","metadata":{"id":"ZEyR1ZF5baPp"},"source":["**Single-element tensors** If you have a one-element tensor, for example\n","by aggregating all values of a tensor into one value, you can convert it\n","to a Python numerical value using `item()`:\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"MHa0xYe3baPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513407720,"user_tz":180,"elapsed":54,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"16953d74-27eb-4121-dd4c-438145a6a37d"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(12.)\n","12.0 <class 'float'>\n"]}],"source":["agg = tensor.sum()\n","print(agg)\n","agg_item = agg.item()\n","print(agg_item, type(agg_item))"]},{"cell_type":"markdown","metadata":{"id":"Ns3cE8ytbaPp"},"source":["**In-place operations** Operations that store the result into the\n","operand are called in-place. They are denoted by a `_` suffix. For\n","example: `x.copy_(y)`, `x.t_()`, will change `x`.\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"uA0FxBSUbaPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513407723,"user_tz":180,"elapsed":2,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"654c1a9b-c670-4746-ac3d-4dff72e00e53"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n"]}],"source":["print(f\"{tensor} \\n\")\n","tensor.add_(5)\n","print(tensor)"]},{"cell_type":"code","source":["tensor.mul_(3)\n","print(tensor )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpB1Z3WnlJiO","executionInfo":{"status":"ok","timestamp":1743513407735,"user_tz":180,"elapsed":11,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"f63e6cff-6b12-4107-f2ad-ac567b252376"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[18., 15., 18., 18.],\n","        [18., 15., 18., 18.],\n","        [18., 15., 18., 18.],\n","        [18., 15., 18., 18.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"il1tWkPGbaPp"},"source":["<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n","\n","<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n","\n","<p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate lossof history. Hence, their use is discouraged.</p>\n","\n","</div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2kepaVjrbaPp"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"9amDhg8YbaPp"},"source":["Bridge with NumPy {#bridge-to-np-label}\n","=================\n","\n","Tensors on the CPU and NumPy arrays can share their underlying memory\n","locations, and changing one will change the other.\n"]},{"cell_type":"markdown","metadata":{"id":"zWsxvxa3baPp"},"source":["Tensor to NumPy array\n","=====================\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"1eFPQeMVbaPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513407754,"user_tz":180,"elapsed":18,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"f6cc6911-61f8-462b-9e87-c564b59ae061"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"Fr1brNCZbaPp"},"source":["A change in the tensor reflects in the NumPy array.\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"NCgkt8LbbaPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513407772,"user_tz":180,"elapsed":18,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"de204411-f582-4b4f-908c-601c093c70c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"J7OwT5DkbaPp"},"source":["NumPy array to Tensor\n","=====================\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"7sXksiB4baPq","executionInfo":{"status":"ok","timestamp":1743513407809,"user_tz":180,"elapsed":36,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}}},"outputs":[],"source":["n = np.ones(5)\n","t = torch.from_numpy(n)"]},{"cell_type":"markdown","metadata":{"id":"-6AoGvzXbaPq"},"source":["Changes in the NumPy array reflects in the tensor.\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"_IjPoFl8baPq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743513407878,"user_tz":180,"elapsed":68,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"bfb98a7e-4316-4208-9c14-8b6ce3db754b"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["np.add(n, 1, out=n) #op no numpy\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/0e6615c5a7bc71e01ff3c51217ea00da/tensorqs_tutorial.ipynb","timestamp":1743445151548}],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}