{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LpuQfiF3wHE2"},"outputs":[],"source":["# For tips on running notebooks in Google Colab, see\n","# https://pytorch.org/tutorials/beginner/colab\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"493HqnQ4wHE3"},"source":["\n","Build the Neural Network\n","========================\n","\n","Neural networks comprise of layers/modules that perform operations on\n","data. The [torch.nn](https://pytorch.org/docs/stable/nn.html) namespace\n","provides all the building blocks you need to build your own neural\n","network. Every module in PyTorch subclasses the\n","[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n","A neural network is a module itself that consists of other modules\n","(layers). This nested structure allows for building and managing complex\n","architectures easily.\n","\n","In the following sections, we\\'ll build a neural network to classify\n","images in the FashionMNIST dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GiafYD4DwHE4"},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","metadata":{"id":"NH2k2GBYwHE4"},"source":["Get Device for Training\n","=======================\n","\n","We want to be able to train our model on an\n","[accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n","such as CUDA, MPS, MTIA, or XPU. If the current accelerator is\n","available, we will use it. Otherwise, we use the CPU.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AEwTX5pMwHE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743516601398,"user_tz":180,"elapsed":20,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"778ad93e-47a0-4f88-df7e-a0e2d10a3744"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n"]}],"source":["device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"6hAbQkRpwHE4"},"source":["Define the Class\n","================\n","\n","We define our neural network by subclassing [nn.Module](https://pytorch.org/docs/stable/nn.html), and initialize\n","the neural network layers in `__init__`. Every `nn.Module` subclass\n","implements the operations on input data in the `forward` method.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGd8FkjdwHE4"},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits"]},{"cell_type":"code","source":["class NeuralNetwork1(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear1 = nn.Linear(28*28, 512)\n","        self.relu1 = nn.ReLU()\n","        self.linear2 = nn.Linear(512, 512)\n","        self.relu2 = nn.ReLU()\n","        self.linear3 = nn.Linear(512, 10)\n","\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.linear1(x)\n","        x = self.relu1(x)\n","        x = self.linear2(x)\n","        x = self.relu2(x)\n","        x= self.linear3(x)\n","        return x"],"metadata":{"id":"xmIi-_BExudu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RI5fh8lHwHE4"},"source":["We create an instance of `NeuralNetwork`, and move it to the `device`,\n","and print its structure.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4AHPJOwwHE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743516601439,"user_tz":180,"elapsed":26,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"e3b66d02-9be3-47fc-de9b-4013ef0d58f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["model = NeuralNetwork().to(device)\n","print(model)"]},{"cell_type":"code","source":["model1 = NeuralNetwork1().to(device)\n","print(model1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQO2fNMFzDJf","executionInfo":{"status":"ok","timestamp":1743516601472,"user_tz":180,"elapsed":32,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"a38e0312-c207-46f1-ae95-f2b5639b9401"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork1(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear1): Linear(in_features=784, out_features=512, bias=True)\n","  (relu1): ReLU()\n","  (linear2): Linear(in_features=512, out_features=512, bias=True)\n","  (relu2): ReLU()\n","  (linear3): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["model1.linear1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKoeM7HRzgfQ","executionInfo":{"status":"ok","timestamp":1743516601513,"user_tz":180,"elapsed":40,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"1a7db4e1-acb7-4112-8177-18312885e11a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=784, out_features=512, bias=True)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["model.linear_relu_stack[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSzc416KzlPA","executionInfo":{"status":"ok","timestamp":1743516601531,"user_tz":180,"elapsed":3,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"719419e2-ccba-473e-c3bd-6c4b62742797"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=784, out_features=512, bias=True)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"jw0kiIkKwHE4"},"source":["To use the model, we pass it the input data. This executes the model\\'s\n","`forward`, along with some [background\n","operations](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866).\n","Do not call `model.forward()` directly!\n","\n","Calling the model on the input returns a 2-dimensional tensor with dim=0\n","corresponding to each output of 10 raw predicted values for each class,\n","and dim=1 corresponding to the individual values of each output. We get\n","the prediction probabilities by passing it through an instance of the\n","`nn.Softmax` module.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_CSnIrbwHE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743516601548,"user_tz":180,"elapsed":15,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"246badc3-e883-4b78-e3a6-fa8fe0b11232"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: tensor([2])\n"]}],"source":["X = torch.rand(1, 28, 28, device=device)\n","logits = model(X)\n","pred_probab = nn.Softmax(dim=1)(logits)\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted class: {y_pred}\")"]},{"cell_type":"markdown","metadata":{"id":"fYKB3iwnwHE5"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"RCQN5e2pwHE5"},"source":["Model Layers\n","============\n","\n","Let\\'s break down the layers in the FashionMNIST model. To illustrate\n","it, we will take a sample minibatch of 3 images of size 28x28 and see\n","what happens to it as we pass it through the network.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74D5HoWKwHE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743516601586,"user_tz":180,"elapsed":38,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"9086b46f-d1cb-4b4e-9a88-e7f58c4fc20a"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 28, 28])\n"]}],"source":["input_image = torch.rand(3,28,28)\n","print(input_image.size())"]},{"cell_type":"markdown","metadata":{"id":"dEmr4BTowHE5"},"source":["nn.Flatten\n","==========\n","\n","We initialize the\n","[nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)\n","layer to convert each 2D 28x28 image into a contiguous array of 784\n","pixel values ( the minibatch dimension (at dim=0) is maintained).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pm02QJY0wHE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743516601668,"user_tz":180,"elapsed":71,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"c9774989-a7e3-4f44-bdfc-fc52a9bf2510"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 784])\n"]}],"source":["flatten = nn.Flatten()\n","flat_image = flatten(input_image)\n","print(flat_image.size())"]},{"cell_type":"markdown","metadata":{"id":"EUd0PzJ-wHE5"},"source":["nn.Linear\n","=========\n","\n","The [linear\n","layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n","is a module that applies a linear transformation on the input using its\n","stored weights and biases.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4O2aDS6OwHE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743516601717,"user_tz":180,"elapsed":2,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"1114ce52-257f-4680-8215-6d26288ebd57"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 20])\n"]}],"source":["layer1 = nn.Linear(in_features=28*28, out_features=20)\n","hidden1 = layer1(flat_image)\n","print(hidden1.size())"]},{"cell_type":"markdown","metadata":{"id":"Ek7OacRvwHE5"},"source":["nn.ReLU\n","=======\n","\n","Non-linear activations are what create the complex mappings between the\n","model\\'s inputs and outputs. They are applied after linear\n","transformations to introduce *nonlinearity*, helping neural networks\n","learn a wide variety of phenomena.\n","\n","In this model, we use\n","[nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n","between our linear layers, but there\\'s other activations to introduce\n","non-linearity in your model.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5rnOCNYwHE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743516601750,"user_tz":180,"elapsed":32,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"56b13715-853d-43eb-ea97-c81726f5a0c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Before ReLU: tensor([[ 0.2682, -0.1597,  0.3539, -0.2127,  0.0328, -0.2040, -0.6202,  0.0778,\n","          0.1004, -0.1096, -0.3607, -0.1318,  0.1259, -0.1800, -0.0935,  0.3136,\n","         -0.1353,  0.5301, -0.0382, -0.0932],\n","        [ 0.2487, -0.0585,  0.3318, -0.3823,  0.2181, -0.4408, -0.5045, -0.3228,\n","          0.0210, -0.2460,  0.0142,  0.1519, -0.0529, -0.2808, -0.2455, -0.0277,\n","         -0.0266,  0.5665, -0.2096, -0.2076],\n","        [ 0.2271, -0.2844,  0.4044,  0.2376,  0.1772, -0.1231, -0.5406, -0.2108,\n","          0.2961, -0.4496, -0.5103, -0.0434, -0.1830, -0.0642, -0.4189, -0.1572,\n","         -0.1928,  0.4381, -0.1534, -0.2797]], grad_fn=<AddmmBackward0>)\n","\n","\n","After ReLU: tensor([[0.2682, 0.0000, 0.3539, 0.0000, 0.0328, 0.0000, 0.0000, 0.0778, 0.1004,\n","         0.0000, 0.0000, 0.0000, 0.1259, 0.0000, 0.0000, 0.3136, 0.0000, 0.5301,\n","         0.0000, 0.0000],\n","        [0.2487, 0.0000, 0.3318, 0.0000, 0.2181, 0.0000, 0.0000, 0.0000, 0.0210,\n","         0.0000, 0.0142, 0.1519, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5665,\n","         0.0000, 0.0000],\n","        [0.2271, 0.0000, 0.4044, 0.2376, 0.1772, 0.0000, 0.0000, 0.0000, 0.2961,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4381,\n","         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"]}],"source":["print(f\"Before ReLU: {hidden1}\\n\\n\")\n","hidden1 = nn.ReLU()(hidden1)\n","print(f\"After ReLU: {hidden1}\")"]},{"cell_type":"markdown","metadata":{"id":"XbWsh_QxwHE5"},"source":["nn.Sequential\n","=============\n","\n","[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n","is an ordered container of modules. The data is passed through all the\n","modules in the same order as defined. You can use sequential containers\n","to put together a quick network like `seq_modules`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KT4vMqguwHE5"},"outputs":[],"source":["seq_modules = nn.Sequential(\n","    flatten,\n","    layer1,\n","    nn.ReLU(),\n","    nn.Linear(20, 10)\n",")\n","input_image = torch.rand(3,28,28)\n","logits = seq_modules(input_image)"]},{"cell_type":"code","source":["logits.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2awyt7B0uHF","executionInfo":{"status":"ok","timestamp":1743516601761,"user_tz":180,"elapsed":2,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"30dffa39-3707-43fe-9d06-433dc521ebff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 10])"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"9lxcpCQTwHE5"},"source":["nn.Softmax\n","==========\n","\n","The last linear layer of the neural network returns [logits]{.title-ref}\n","- raw values in \\[-infty, infty\\] - which are passed to the\n","[nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)\n","module. The logits are scaled to values \\[0, 1\\] representing the\n","model\\'s predicted probabilities for each class. `dim` parameter\n","indicates the dimension along which the values must sum to 1.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dO1Boy9hwHE5"},"outputs":[],"source":["softmax = nn.Softmax(dim=1)\n","pred_probab = softmax(logits)"]},{"cell_type":"code","source":["pred_probab.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Do5RLn50mtx","executionInfo":{"status":"ok","timestamp":1743516601764,"user_tz":180,"elapsed":2,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"300b5353-6363-4d9a-eb7b-9065e92ae7b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 10])"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"RpNNt-7twHE5"},"source":["Model Parameters\n","================\n","\n","Many layers inside a neural network are *parameterized*, i.e. have\n","associated weights and biases that are optimized during training.\n","Subclassing `nn.Module` automatically tracks all fields defined inside\n","your model object, and makes all parameters accessible using your\n","model\\'s `parameters()` or `named_parameters()` methods.\n","\n","In this example, we iterate over each parameter, and print its size and\n","a preview of its values.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVqJNhcIwHE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743516601796,"user_tz":180,"elapsed":32,"user":{"displayName":"Maynara Donato de Souza","userId":"16000170203051918625"}},"outputId":"a836cb32-0fe8-4951-f4b4-3b699ef8c566"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model structure: NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","\n","\n","Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0135, -0.0097,  0.0230,  ...,  0.0200, -0.0322,  0.0263],\n","        [ 0.0307,  0.0063,  0.0342,  ...,  0.0289,  0.0311, -0.0097]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0015, -0.0236], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0036, -0.0113,  0.0037,  ..., -0.0384,  0.0318,  0.0243],\n","        [ 0.0428,  0.0403,  0.0212,  ...,  0.0071,  0.0078, -0.0214]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0267, 0.0093], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0074, -0.0438, -0.0373,  ..., -0.0329, -0.0095,  0.0015],\n","        [-0.0423,  0.0343, -0.0400,  ...,  0.0225,  0.0092, -0.0389]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0300,  0.0018], grad_fn=<SliceBackward0>) \n","\n"]}],"source":["print(f\"Model structure: {model}\\n\\n\")\n","\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"cCg4ZaaFwHE5"},"source":["------------------------------------------------------------------------\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/76d764ad694d0795e494a1edbfb068a6/buildmodel_tutorial.ipynb","timestamp":1743450573591}]}},"nbformat":4,"nbformat_minor":0}